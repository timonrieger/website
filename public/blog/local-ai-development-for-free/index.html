<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=Strict-Transport-Security content="max-age=31536000; includeSubDomains; preload"><meta http-equiv=X-XSS-Protection content="1; mode=block"><meta http-equiv=X-Frame-Options content="DENY"><meta name=robots content="index, follow"><title>Local AI Development for Free | timonrieger.de</title>
<meta name=keywords content="programming"><meta name=description content="In this short article, I&rsquo;ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process."><meta name=author content><link rel=canonical href=https://timonrieger.de/blog/local-ai-development-for-free/><link crossorigin=anonymous href=/assets/css/stylesheet.2fe458a3004f8122f56c00eeaae85d03fd6036018b5ff83371839dbc87d5e2de.css integrity="sha256-L+RYowBPgSL1bADuquhdA/1gNgGLX/gzcYOdvIfV4t4=" rel="preload stylesheet" as=style><link rel=icon href=https://timonrieger.de/assets/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://timonrieger.de/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://timonrieger.de/favicon-32x32.png><link rel=apple-touch-icon href=https://timonrieger.de/apple-touch-icon.png><link rel=mask-icon href=https://timonrieger.de/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://timonrieger.de/blog/local-ai-development-for-free/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://timonrieger.de/blog/local-ai-development-for-free/"><meta property="og:site_name" content="timonrieger.de"><meta property="og:title" content="Local AI Development for Free"><meta property="og:description" content="In this short article, I’ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-02-11T21:39:48+01:00"><meta property="article:modified_time" content="2025-03-16T08:08:22+00:00"><meta property="article:tag" content="Programming"><meta property="og:image" content="https://timonrieger.de/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://timonrieger.de/images/papermod-cover.png"><meta name=twitter:title content="Local AI Development for Free"><meta name=twitter:description content="In this short article, I&rsquo;ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://timonrieger.de/blog/"},{"@type":"ListItem","position":2,"name":"Local AI Development for Free","item":"https://timonrieger.de/blog/local-ai-development-for-free/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Local AI Development for Free","name":"Local AI Development for Free","description":"In this short article, I\u0026rsquo;ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process.\n","keywords":["programming"],"articleBody":"In this short article, I’ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process.\nQuote Of The Day The only mistake is almost always to believe that my point of view is the only one from which one can see the truth. The deaf person will always think the dancers are crazy.\nI recently started using Jan AI to develop locally with AI (and also for daily use). Basically, you can use Jan as the frontend for any GGUF LLM. It stores the model and all the conversations on your local machine making it private and great for developing as you can launch a OpenAI compatible API and thus don’t need to pay for the API.\nAfter downloading the Jan desktop app, installing a model of your choice and starting the server in the UI, you can test it by running the following script:\nimport openai client = openai.OpenAI(api_key='APIKEY', base_url='http://127.0.0.1:1337/v1') response = client.chat.completions.create( model=\"qwen2.5-coder-7b-instruct\", messages=[ {\"role\": \"system\", \"content\": \"You are a Journalist\"}, {\"role\": \"assistant\", \"content\": \"Write a short article\"}, {\"role\": \"user\", \"content\": \"what is a computer?\"} ], ) response = response.choices[0].message.content print(response) This will print the response from the LLM in the console.\nNote: You need to replace the model with the model you installed in the Jan UI. You can find the id with client.models.list().\nFrom now on you can use the openai library to interact with your local LLM. Happy coding!\n","wordCount":"265","inLanguage":"en","image":"https://timonrieger.de/images/papermod-cover.png","datePublished":"2025-02-11T21:39:48+01:00","dateModified":"2025-03-16T08:08:22Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://timonrieger.de/blog/local-ai-development-for-free/"},"publisher":{"@type":"Organization","name":"timonrieger.de","logo":{"@type":"ImageObject","url":"https://timonrieger.de/assets/favicon.ico"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://timonrieger.de/ accesskey=h title="timonrieger.de (Alt + H)">timonrieger.de</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://timonrieger.de/about/ title=About><span>About</span></a></li><li><a href=https://timonrieger.de/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://timonrieger.de/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://timonrieger.de/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://timonrieger.de/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://timonrieger.de/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://timonrieger.de/photos/ title=Photos><span>Photos</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://timonrieger.de/>Home</a>&nbsp;»&nbsp;<a href=https://timonrieger.de/blog/>Blog</a></div><h1 class="post-title entry-hint-parent">Local AI Development for Free</h1><div class=post-meta><span title='2025-02-11 21:39:48 +0100 +0100'>Feb 11, 2025</span>&nbsp;·&nbsp;<span title='2025-03-16 08:08:22 +0000 UTC'>updated on Mar 16, 2025</span>&nbsp;·&nbsp;2 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#quote-of-the-day aria-label="Quote Of The Day">Quote Of The Day</a></li></ul></div></details></div><div class=post-content><p>In this short article, I&rsquo;ll show you how to develop locally with LLMs, making AI development free and private. With the rising costs of AI services, running models locally is becoming an increasingly attractive option for developers who want full control over their AI development process.</p><h2 id=quote-of-the-day>Quote Of The Day<a hidden class=anchor aria-hidden=true href=#quote-of-the-day>#</a></h2><blockquote><p>The only mistake is almost always to believe that my point of view is the only one from which one can see the truth. The deaf person will always think the dancers are crazy.</p></blockquote><hr><p>I recently started using <a href=https://jan.ai>Jan AI</a> to develop locally with AI (and also for daily use). Basically, you can use Jan as the frontend for any GGUF LLM. It stores the model and all the conversations on your local machine making it private and great for developing as you can launch a OpenAI compatible API and thus don&rsquo;t need to pay for the API.</p><p>After downloading the Jan desktop app, installing a model of your choice and starting the server in the UI, you can test it by running the following script:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s1>&#39;APIKEY&#39;</span><span class=p>,</span> <span class=n>base_url</span><span class=o>=</span><span class=s1>&#39;http://127.0.0.1:1337/v1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;qwen2.5-coder-7b-instruct&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;You are a Journalist&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Write a short article&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;what is a computer?&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span></code></pre></div><p>This will print the response from the LLM in the console.</p><blockquote><p>Note: You need to replace the <code>model</code> with the model you installed in the Jan UI. You can find the id with <code>client.models.list()</code>.</p></blockquote><p>From now on you can use the openai library to interact with your local LLM. Happy coding!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://timonrieger.de/tags/programming/>Programming</a></li></ul><nav class=paginav><a class=next href=https://timonrieger.de/blog/building-a-betting-strategy-2/><span class=title>Next »</span><br><span>Building a Betting Strategy (2)</span></a></nav></footer></article></main><footer class=footer><span>© Timon Rieger</span> ·
<a href=https://stats.uptimerobot.com/nrF9tU3KtX>Status</a> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>